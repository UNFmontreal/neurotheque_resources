{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Working with AutoReject Logs\n",
       "\n",
       "This notebook demonstrates how to load and work with AutoReject logs that have been saved during preprocessing, with a focus on the enhanced visualization capabilities."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import sys\n",
       "import os\n",
       "import pickle\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "from pathlib import Path\n",
       "\n",
       "# Add the project root to the path\n",
       "sys.path.insert(0, os.path.abspath(os.path.join('..',)))\n",
       "\n",
       "# Import our utility functions\n",
       "from scr.utils.autoreject_utils import find_autoreject_log, load_autoreject_log, plot_autoreject_summary, plot_reject_log"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Finding and Loading AutoReject Logs\n",
       "\n",
       "First, let's try to find any existing AutoReject logs for our subjects."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Define the subject and session\n",
       "subject_id = \"01\"\n",
       "session_id = \"001\"\n",
       "task_id = \"5pt\"\n",
       "run_id = \"01\"\n",
       "\n",
       "# Find the AutoReject log\n",
       "log_path = find_autoreject_log(\n",
       "    subject_id=subject_id,\n",
       "    session_id=session_id,\n",
       "    task_id=task_id,\n",
       "    run_id=run_id,\n",
       "    base_dir=os.path.abspath('..')\n",
       ")\n",
       "\n",
       "print(f\"Found AutoReject log at: {log_path}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load the AutoReject log\n",
       "reject_log = load_autoreject_log(log_path)\n",
       "\n",
       "# If the log wasn't found by path, we can try by subject/session\n",
       "if reject_log is None:\n",
       "    reject_log = load_autoreject_log(\n",
       "        subject_id=subject_id,\n",
       "        session_id=session_id,\n",
       "        task_id=task_id,\n",
       "        run_id=run_id,\n",
       "        base_dir=os.path.abspath('..')\n",
       "    )"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Exploring the AutoReject Log Structure\n",
       "\n",
       "Let's look at the attributes and methods of the loaded RejectLog object."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Check if we successfully loaded a log\n",
       "if reject_log is None:\n",
       "    print(\"No AutoReject log was found. Skipping this section.\")\n",
       "else:\n",
       "    # Print the main attributes\n",
       "    print(\"\\nAutoReject Log Attributes:\")\n",
       "    for attr in dir(reject_log):\n",
       "        if not attr.startswith('__'):\n",
       "            try:\n",
       "                value = getattr(reject_log, attr)\n",
       "                if not callable(value):\n",
       "                    if isinstance(value, (np.ndarray, list)) and len(str(value)) > 100:\n",
       "                        print(f\"{attr}: {type(value)} - (large array/list)\")\n",
       "                    else:\n",
       "                        print(f\"{attr}: {type(value)} - {value}\")\n",
       "                else:\n",
       "                    print(f\"{attr}: {type(value)} - (method)\")\n",
       "            except Exception as e:\n",
       "                print(f\"{attr}: Error - {e}\")\n",
       "    \n",
       "    # Print more details about key attributes\n",
       "    print(\"\\nDetailed information:\")\n",
       "    print(f\"Number of epochs: {len(reject_log.bad_epochs)}\")\n",
       "    print(f\"Number of bad epochs: {np.sum(reject_log.bad_epochs)}\")\n",
       "    print(f\"Percentage of bad epochs: {np.mean(reject_log.bad_epochs) * 100:.1f}%\")\n",
       "    print(f\"Number of channels: {len(reject_log.ch_names)}\")\n",
       "    \n",
       "    # Print the first few bad epochs\n",
       "    bad_indices = np.where(reject_log.bad_epochs)[0]\n",
       "    if len(bad_indices) > 0:\n",
       "        print(f\"\\nIndices of first 5 bad epochs: {bad_indices[:5]}\")\n",
       "    else:\n",
       "        print(\"\\nNo bad epochs found\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Visualizing the AutoReject Results with Enhanced Plots\n",
       "\n",
       "Let's create different visualizations of the AutoReject results using our enhanced plotting functions."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if reject_log is not None:\n",
       "    # Create a comprehensive visualization using our enhanced function\n",
       "    fig = plot_autoreject_summary(reject_log)\n",
       "    plt.show()\n",
       "    \n",
       "    # We can also save the figure\n",
       "    # plot_autoreject_summary(reject_log, save_to='autoreject_summary.png')\n",
       "else:\n",
       "    print(\"No AutoReject log was found. Cannot create visualization.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.1 Enhanced RejectLog Plot\n",
       "\n",
       "This plot is an enhanced version of the original RejectLog's plot method, with better visibility of channel names and improved readability."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if reject_log is not None:\n",
       "    # Use our enhanced version of the RejectLog's plot method\n",
       "    fig = plot_reject_log(reject_log, orientation='horizontal')\n",
       "    plt.show()\n",
       "    \n",
       "    # Let's also try the vertical orientation\n",
       "    fig = plot_reject_log(reject_log, orientation='vertical')\n",
       "    plt.show()\n",
       "else:\n",
       "    print(\"No AutoReject log was found. Cannot create visualization.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.2 Compare Visualization Methods\n",
       "\n",
       "Let's compare the different visualization methods to see which one works best for your data."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if reject_log is not None:\n",
       "    print(\"Creating all visualization types for comparison...\")\n",
       "    \n",
       "    # 1. Original RejectLog's plot method\n",
       "    plt.figure(figsize=(15, 10))\n",
       "    fig1 = reject_log.plot(show=False)\n",
       "    fig1.suptitle('Original RejectLog Plot', fontsize=16)\n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    \n",
       "    # 2. Enhanced RejectLog plot\n",
       "    fig2 = plot_reject_log(reject_log, orientation='horizontal')\n",
       "    plt.show()\n",
       "    \n",
       "    # 3. Comprehensive summary visualization\n",
       "    fig3 = plot_autoreject_summary(reject_log)\n",
       "    plt.show()\n",
       "    \n",
       "    print(\"Which visualization style do you prefer? You can use these in your analysis pipeline.\")\n",
       "else:\n",
       "    print(\"No AutoReject log was found. Cannot create visualizations.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Using AutoReject Results with Raw Data\n",
       "\n",
       "Now let's demonstrate how to use the AutoReject log with raw data to create epochs that exclude the bad epochs."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import mne\n",
       "\n",
       "# Load the preprocessed data\n",
       "data_path = os.path.join('..', 'data', 'processed', f'sub-{subject_id}', f'ses-{session_id}', \n",
       "                         f'sub-{subject_id}_ses-{session_id}_task-{task_id}_run-{run_id}_after_autoreject.fif')\n",
       "\n",
       "# Check if the file exists\n",
       "if os.path.exists(data_path):\n",
       "    # Load the data\n",
       "    raw = mne.io.read_raw_fif(data_path, preload=True)\n",
       "    print(f\"Loaded data from {data_path}\")\n",
       "    \n",
       "    # Create fixed-length events for epoching\n",
       "    events = mne.make_fixed_length_events(raw, duration=1.0)\n",
       "    \n",
       "    # Create epochs\n",
       "    epochs = mne.Epochs(raw, events, tmin=0, tmax=1, baseline=None, preload=True)\n",
       "    print(f\"Created {len(epochs)} epochs\")\n",
       "    \n",
       "    # If we have a reject_log, use it to exclude bad epochs\n",
       "    if reject_log is not None and len(reject_log.bad_epochs) == len(epochs):\n",
       "        # Create a mask for good epochs\n",
       "        good_mask = ~reject_log.bad_epochs\n",
       "        \n",
       "        # Select only good epochs\n",
       "        good_epochs = epochs[good_mask]\n",
       "        print(f\"Selected {len(good_epochs)}/{len(epochs)} good epochs using AutoReject log\")\n",
       "        \n",
       "        # We can now use these good epochs for further analysis\n",
       "        # For example, let's compute a PSD\n",
       "        fig = good_epochs.plot_psd(fmax=40, average=True)\n",
       "    else:\n",
       "        print(\"No AutoReject log available or the number of epochs doesn't match.\")\n",
       "        print(f\"Reject log epochs: {None if reject_log is None else len(reject_log.bad_epochs)}\")\n",
       "        print(f\"Created epochs: {len(epochs)}\")\n",
       "else:\n",
       "    print(f\"Data file not found at {data_path}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Additional Enhanced Visualizations\n",
       "\n",
       "Let's create a few more specialized visualizations to better understand the AutoReject results."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if reject_log is not None:\n",
       "    # Extract rejection data\n",
       "    bad_epochs = reject_log.bad_epochs\n",
       "    ch_names = reject_log.ch_names\n",
       "    \n",
       "    # Get the detailed labels if available\n",
       "    if hasattr(reject_log, 'labels') and reject_log.labels is not None:\n",
       "        labels = reject_log.labels\n",
       "        \n",
       "        # Calculate statistics per channel\n",
       "        channel_stats = {}\n",
       "        for i, ch in enumerate(ch_names):\n",
       "            good = np.sum(labels[:, i] == 0)\n",
       "            interpolated = np.sum(labels[:, i] == 1)\n",
       "            bad = np.sum(labels[:, i] == 2)\n",
       "            total = len(bad_epochs)\n",
       "            channel_stats[ch] = {\n",
       "                'good_percent': good / total * 100,\n",
       "                'interpolated_percent': interpolated / total * 100,\n",
       "                'bad_percent': bad / total * 100\n",
       "            }\n",
       "        \n",
       "        # Create a stacked bar chart of channel quality\n",
       "        plt.figure(figsize=(12, 10))\n",
       "        channels = list(channel_stats.keys())\n",
       "        good_vals = [channel_stats[ch]['good_percent'] for ch in channels]\n",
       "        interp_vals = [channel_stats[ch]['interpolated_percent'] for ch in channels]\n",
       "        bad_vals = [channel_stats[ch]['bad_percent'] for ch in channels]\n",
       "        \n",
       "        # Sort channels by quality (highest percentage of good data first)\n",
       "        sorted_indices = np.argsort(good_vals)\n",
       "        channels = [channels[i] for i in sorted_indices]\n",
       "        good_vals = [good_vals[i] for i in sorted_indices]\n",
       "        interp_vals = [interp_vals[i] for i in sorted_indices]\n",
       "        bad_vals = [bad_vals[i] for i in sorted_indices]\n",
       "        \n",
       "        # Create stacked bar chart\n",
       "        plt.barh(channels, good_vals, color='green', alpha=0.7, label='Good')\n",
       "        plt.barh(channels, interp_vals, left=good_vals, color='blue', alpha=0.7, label='Interpolated')\n",
       "        plt.barh(channels, bad_vals, left=np.array(good_vals) + np.array(interp_vals), \n",
       "                color='red', alpha=0.7, label='Bad')\n",
       "        \n",
       "        plt.xlabel('Percentage (%)', fontsize=12)\n",
       "        plt.ylabel('Channels', fontsize=12)\n",
       "        plt.title('Channel Data Quality Overview', fontsize=14, fontweight='bold')\n",
       "        plt.legend(loc='lower right')\n",
       "        plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
       "        plt.xlim(0, 100)\n",
       "        plt.tight_layout()\n",
       "        plt.show()\n",
       "        \n",
       "        # Create a heatmap of epochs x channels showing quality over time\n",
       "        plt.figure(figsize=(18, 10))\n",
       "        plt.imshow(labels.T, aspect='auto', cmap='RdYlGn_r', vmin=0, vmax=2)\n",
       "        plt.colorbar(ticks=[0, 1, 2], label='Status (0=Good, 1=Interpolated, 2=Bad)')\n",
       "        plt.xlabel('Epochs (Time →)', fontsize=12)\n",
       "        plt.ylabel('Channels', fontsize=12)\n",
       "        plt.yticks(range(len(ch_names)), ch_names)\n",
       "        plt.title('Channel Quality Over Time', fontsize=14, fontweight='bold')\n",
       "        \n",
       "        # Add grid for better readability\n",
       "        plt.grid(False)\n",
       "        \n",
       "        # Add horizontal lines between channels\n",
       "        for i in range(1, len(ch_names)):\n",
       "            plt.axhline(i - 0.5, color='black', linewidth=0.5, alpha=0.3)\n",
       "            \n",
       "        # Add epoch markings every 50 epochs\n",
       "        for i in range(0, len(bad_epochs), 50):\n",
       "            plt.axvline(i, color='black', linewidth=0.5, alpha=0.3)\n",
       "            \n",
       "        plt.tight_layout()\n",
       "        plt.show()\n",
       "    else:\n",
       "        print(\"Detailed channel-level information not available in this RejectLog.\")\n",
       "else:\n",
       "    print(\"No AutoReject log was found. Cannot create visualizations.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Summary\n",
       "\n",
       "In this notebook, we demonstrated how to:\n",
       "1. Find and load AutoReject logs saved during preprocessing\n",
       "2. Explore the structure and attributes of the AutoReject log\n",
       "3. Create enhanced visualizations of the AutoReject results using multiple approaches\n",
       "4. Use the AutoReject log to select good epochs from raw data\n",
       "5. Create specialized visualizations to better understand channel-level and epoch-level quality\n",
       "\n",
       "These techniques allow you to get a much clearer picture of your data quality and consistently apply the same epoch rejection across different analyses, ensuring reproducibility."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "eeg_analysis",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }