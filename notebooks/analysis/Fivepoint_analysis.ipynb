{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five-Point Task — Cleaned EEG Analysis\n",
    "\n",
    "This notebook loads ICA/AutoReject-cleaned five-point data, extracts stimulus- and response-locked epochs, applies robust pre-event z-scoring, and generates ERPs and time–frequency summaries. Settings follow slow-wave friendly filters (HPF 0.1–0.3 Hz, LPF 40 Hz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import yaml\n",
    "\n",
    "# Add repo root to path for scr/* imports\n",
    "ROOT = Path('..').resolve().parents[0]  # project root\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from scr.steps.project_paths import ProjectPaths\n",
    "\n",
    "mne.set_log_level('INFO')\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "plt.rcParams['figure.dpi'] = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "cfg_path = ROOT / 'configs' / 'fivepoint_pipeline.yml'\n",
    "with open(cfg_path, 'r') as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "\n",
    "sub = CFG.get('default_subject', '01')\n",
    "ses = CFG.get('default_session', '001')\n",
    "task = '5pt'\n",
    "run = CFG.get('default_run', '01')\n",
    "\n",
    "paths = ProjectPaths(CFG)\n",
    "RAW_DIR = Path(CFG['directory']['root']) / CFG['directory']['raw_data_dir']\n",
    "PROC_DIR = Path(CFG['directory']['root']) / CFG['directory']['processed_dir']\n",
    "REPORTS_DIR = Path(CFG['directory']['root']) / CFG['directory']['reports_dir']\n",
    "\n",
    "report_dir = REPORTS_DIR / 'fivepoint' / 'analysis' / sub / ses / f'task-{task}' / f'run-{run}'\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('PROC_DIR:', PROC_DIR)\n",
    "print('Report dir:', report_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading helpers\n",
    "def try_read_raw(path: Path):\n",
    "    if path.exists():\n",
    "        try:\n",
    "            if path.suffix.lower() == '.edf':\n",
    "                return mne.io.read_raw_edf(path, preload=True)\n",
    "            return mne.io.read_raw_fif(path, preload=True)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to read raw: {path} -> {e}')\n",
    "    return None\n",
    "\n",
    "def try_read_epochs(path: Path):\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return mne.read_epochs(path, preload=True, verbose=False)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to read epochs: {path} -> {e}')\n",
    "    return None\n",
    "\n",
    "# Candidate files (most to least preferred)\n",
    "cand_epochs = [\n",
    "    PROC_DIR / f'sub-{sub}' / f'ses-{ses}' / f'sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-ica_epo.fif',\n",
    "    PROC_DIR / 'autoreject' / f'sub-{sub}_ses-{ses}_run-{run}_ar_final_pass_epo.fif',\n",
    "    PROC_DIR / f'sub-{sub}' / f'ses-{ses}' / f'sub-{sub}_ses-{ses}_task-{task}_run-{run}_preprocessed-epoched.fif',\n",
    "]\n",
    "\n",
    "cand_raw = [\n",
    "    PROC_DIR / f'sub-{sub}' / f'ses-{ses}' / f'sub-{sub}_ses-{ses}_desc-ica_cleaned.fif',\n",
    "    RAW_DIR / f'sub-{sub}_ses-{ses}_task-{task}_run-{run}_raw.edf',\n",
    "]\n",
    "\n",
    "epochs = None\n",
    "for p in cand_epochs:\n",
    "    epochs = try_read_epochs(p)\n",
    "    if epochs is not None:\n",
    "        print('Loaded epochs:', p)\n",
    "        break\n",
    "\n",
    "raw = None if epochs is not None else None\n",
    "if epochs is None:\n",
    "    for p in cand_raw:\n",
    "        raw = try_read_raw(p)\n",
    "        if raw is not None:\n",
    "            print('Loaded raw:', p)\n",
    "            break\n",
    "\n",
    "if (epochs is None) and (raw is None):\n",
    "    raise FileNotFoundError('Could not find cleaned epochs or raw for five-point task. Check paths.')\n",
    "\n",
    "raw if raw is not None else epochs.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter settings to preserve slow components\n",
    "HPF = 0.1\n",
    "LPF = 40.0\n",
    "\n",
    "if raw is None:\n",
    "    # If we already have epochs, ensure they were filtered reasonably; optionally refilter\n",
    "    print('Using precomputed epochs; skipping refilter of raw.')\n",
    "    sfreq = epochs.info['sfreq']\n",
    "    picks_eeg = mne.pick_types(epochs.info, eeg=True, eog=True)\n",
    "else:\n",
    "    print(f'Filtering raw: {HPF}–{LPF} Hz (zero-phase)')\n",
    "    raw = raw.copy().filter(l_freq=HPF, h_freq=LPF, phase='zero-double', fir_design='firwin')\n",
    "    sfreq = raw.info['sfreq']\n",
    "    picks_eeg = mne.pick_types(raw.info, eeg=True, eog=True)\n",
    "\n",
    "sfreq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five-point event extraction (pattern-based)\n",
    "# Assumptions: all triggers share a code (often 8); first=START, last=END; middle alternate onset/response\n",
    "STIM_CH = 'Trigger'\n",
    "ONSET_CODE = 801\n",
    "RESP_CODE = 802\n",
    "\n",
    "def extract_5pt_events(raw_like):\n",
    "    ev = mne.find_events(raw_like, stim_channel=STIM_CH, shortest_event=1, verbose=True)\n",
    "    if len(ev) < 3:\n",
    "        raise RuntimeError('Not enough events detected for 5PT (need at least start, one pair, end).')\n",
    "    sf = raw_like.info['sfreq']\n",
    "    # First and last as boundary\n",
    "    start, end = ev[0], ev[-1]\n",
    "    middle = ev[1:-1]\n",
    "    onset_ev, resp_ev = [], []\n",
    "    for i, e in enumerate(middle):\n",
    "        if i % 2 == 0:\n",
    "            onset_ev.append(e.copy())\n",
    "        else:\n",
    "            resp_ev.append(e.copy())\n",
    "    # Truncate to pairs\n",
    "    n = min(len(onset_ev), len(resp_ev))\n",
    "    onset_ev, resp_ev = onset_ev[:n], resp_ev[:n]\n",
    "    # Make coded event arrays\n",
    "    on = np.array([[e[0], 0, ONSET_CODE] for e in onset_ev], dtype=int) if n>0 else np.empty((0,3), int)\n",
    "    rp = np.array([[e[0], 0, RESP_CODE] for e in resp_ev], dtype=int) if n>0 else np.empty((0,3), int)\n",
    "    # Reaction times in seconds\n",
    "    rts = (np.array([r[0] for r in resp_ev]) - np.array([o[0] for o in onset_ev])) / sf if n>0 else np.array([])\n",
    "    return on, rp, rts, start, end\n",
    "\n",
    "if epochs is not None and hasattr(epochs, 'events') and epochs.events is not None:\n",
    "    # If epochs exist but we still want response-locked, re-derive from underlying raw\n",
    "    raw_for_events = epochs.copy().average()._project_as_onto_raw() if hasattr(epochs, 'copy') else None\n",
    "    # Fallback: try to use epochs._raw if present (MNE stores original Raw in private attr sometimes)\n",
    "    if raw_for_events is None and hasattr(epochs, '_raw') and epochs._raw is not None:\n",
    "        raw_for_events = epochs._raw\n",
    "else:\n",
    "    raw_for_events = raw\n",
    "\n",
    "on_events, resp_events, RTs, start_evt, end_evt = extract_5pt_events(raw_for_events)\n",
    "print(f'N onset={len(on_events)}, N response={len(resp_events)}')\n",
    "print(f'RT: mean={RTs.mean():.3f}s, median={np.median(RTs):.3f}s')\n",
    "\n",
    "# RT trimming: remove <150 ms and >95th percentile\n",
    "rt_lo, rt_hi = 0.150, np.percentile(RTs, 95) if len(RTs) else (0.150, 0.0)\n",
    "keep = (RTs >= rt_lo) & (RTs <= rt_hi) if len(RTs) else np.array([], dtype=bool)\n",
    "on_events_trim = on_events[keep] if len(keep) else on_events\n",
    "resp_events_trim = resp_events[keep] if len(keep) else resp_events\n",
    "RTs_trim = RTs[keep] if len(keep) else RTs\n",
    "print(f'Kept {keep.sum() if len(RTs) else len(on_events)} trials after RT trimming')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoching: stimulus-locked and response-locked\n",
    "tmin_stim, tmax_stim = -0.5, 3.0\n",
    "tmin_resp, tmax_resp = -2.0, 0.8\n",
    "\n",
    "if raw is not None:\n",
    "    e_stim = mne.Epochs(raw, on_events_trim, event_id={'onset': ONSET_CODE},\n",
    "                        tmin=tmin_stim, tmax=tmax_stim, baseline=None, preload=True)\n",
    "    e_resp = mne.Epochs(raw, resp_events_trim, event_id={'resp': RESP_CODE},\n",
    "                        tmin=tmin_resp, tmax=tmax_resp, baseline=None, preload=True)\n",
    "else:\n",
    "    # If we already have onset-centered epochs, re-epoch response-locked from raw_for_events if possible\n",
    "    e_stim = mne.EpochsArray(epochs.get_data(), info=epochs.info, events=on_events_trim,\n",
    "                             tmin=tmin_stim) if False else epochs.copy()  # keep existing stim epochs\n",
    "    if raw_for_events is not None:\n",
    "        e_resp = mne.Epochs(raw_for_events, resp_events_trim, event_id={'resp': RESP_CODE},\n",
    "                            tmin=tmin_resp, tmax=tmax_resp, baseline=None, preload=True)\n",
    "    else:\n",
    "        raise RuntimeError('Cannot create response-locked epochs without access to raw-like data.')\n",
    "\n",
    "e_stim, e_resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust pre-event z-scoring\n",
    "def robust_z(epochs, tmin_ref, tmax_ref):\n",
    "    X = epochs.get_data()  # (n_ep, n_ch, n_time)\n",
    "    times = epochs.times\n",
    "    ref = (times >= tmin_ref) & (times <= tmax_ref)\n",
    "    refdat = X[:, :, ref].reshape(len(epochs), X.shape[1], -1)\n",
    "    med = np.median(refdat, axis=(0,2), keepdims=True)\n",
    "    mad = np.median(np.abs(refdat - med), axis=(0,2), keepdims=True)\n",
    "    # Avoid zeros; use global median of positive MADs as floor\n",
    "    mad_pos = mad[mad>0]\n",
    "    floor = np.nanmedian(mad_pos) if mad_pos.size else 1.0\n",
    "    scale = 1.4826 * np.maximum(mad, floor)\n",
    "    Z = (X - med) / scale\n",
    "    eZ = epochs.copy()\n",
    "    eZ._data = Z\n",
    "    return eZ\n",
    "\n",
    "e_stimZ = robust_z(e_stim, -0.6, -0.1)\n",
    "e_respZ = robust_z(e_resp, -1.2, -0.2)\n",
    "e_stimZ, e_respZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERPs: quick looks\n",
    "roi_occ = ['O1','O2','PO7','PO8']\n",
    "roi_cpar = ['CPz','Pz','CP1','CP2','P1','P2']\n",
    "roi_cen = ['Cz']\n",
    "\n",
    "def safe_picks(info, names):\n",
    "    return [ch for ch in names if ch in info.ch_names]\n",
    "\n",
    "ev_stim = e_stimZ.average()\n",
    "ev_resp = e_respZ.average()\n",
    "\n",
    "fig1 = ev_stim.plot(picks=safe_picks(ev_stim.info, roi_occ), titles='Stim-locked: Occipital (P1/N1)', show=False)\n",
    "fig2 = ev_stim.plot(picks=safe_picks(ev_stim.info, roi_cpar), titles='Stim-locked: Centro-parietal (P3/CNV)', show=False)\n",
    "fig3 = ev_resp.plot(picks=safe_picks(ev_resp.info, roi_cen), titles='Response-locked: MRCP/BP @ Cz', show=False)\n",
    "\n",
    "fig_dir = report_dir / 'figures'\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "fig1.savefig(fig_dir / 'erp_stim_occ.png'); plt.close(fig1)\n",
    "fig2.savefig(fig_dir / 'erp_stim_cpar.png'); plt.close(fig2)\n",
    "fig3.savefig(fig_dir / 'erp_resp_cz.png'); plt.close(fig3)\n",
    "print('Saved ERP figures to', fig_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRP (C3 - C4) if both present\n",
    "if all(ch in e_respZ.info.ch_names for ch in ['C3','C4']):\n",
    "    ev_resp_c3 = e_respZ.copy().pick(['C3']).average()\n",
    "    ev_resp_c4 = e_respZ.copy().pick(['C4']).average()\n",
    "    lrp = ev_resp_c3.data.squeeze() - ev_resp_c4.data.squeeze()\n",
    "    plt.figure(); plt.plot(ev_resp.times, lrp)\n",
    "    plt.axvline(0, color='k', ls='--'); plt.title('LRP (C3 - C4), response-locked')\n",
    "    plt.xlabel('Time (s)'); plt.ylabel('Z (a.u.)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / 'lrp_resp.png'); plt.close()\n",
    "    print('Saved LRP figure')\n",
    "else:\n",
    "    print('C3/C4 not both available; skipping LRP.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time–Frequency (Morlet) — response-locked for mu/beta ERD and PMBR\n",
    "freqs = np.arange(2, 40, 1.0)\n",
    "n_cycles = freqs / 2.0\n",
    "picks_sens = mne.pick_types(e_respZ.info, eeg=True, eog=False)\n",
    "tfr_resp = mne.time_frequency.tfr_morlet(e_respZ.copy().pick(picks_sens),\n",
    "                                         freqs=freqs, n_cycles=n_cycles,\n",
    "                                         use_fft=True, return_itc=False, average=True, n_jobs=1)\n",
    "# Baseline in TF usually in dB, but here epochs already z-scored; skip further baseline\n",
    "tfr_fig = tfr_resp.plot(picks='Cz' if 'Cz' in e_respZ.ch_names else None,\n",
    "                        title='Response-locked TFR', show=False)\n",
    "tfr_path = fig_dir / 'tfr_resp.png'\n",
    "tfr_fig[0].savefig(tfr_path) if isinstance(tfr_fig, list) else tfr_fig.savefig(tfr_path)\n",
    "plt.close('all')\n",
    "print('Saved TFR figure to', tfr_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export per-trial table (RTs and basic metadata)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'trial': np.arange(len(RTs_trim)),\n",
    "    'RT_s': RTs_trim\n",
    "})\n",
    "csv_path = report_dir / 'fivepoint_trials.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('Saved trial table to', csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

